import os
import os.path
import cPickle as pickle
import time

from cheshire3.exceptions import ObjectDoesNotExistException

BASE_DIR = os.path.dirname(__file__)
CLIC_DIR = os.path.abspath(os.path.join(BASE_DIR, '..'))


class Chapter():
    """
    Abstracts a cheshire3 Chapter record, performing all lookups CLiC needs

    Designed to be picked and re-used to save work

    Attributes:
    - digest: The cheshire3 digest for the document
    - tokens: Array of word / non-word tokens
    - word_map: Array of positions in tokens that contain words, i.e. tokens[word_map[4]] is the 4th word
    """
    def __init__(self, dom, digest):
        """
        Create object
        - dom: The lxml Root node for the chapter (a div)
        - digest: The record digest, used to check for updates
        """
        self.digest = digest
        ch_node = dom.xpath('/div')[0]

        self.tokens = []
        self.word_map = []
        for n in dom.xpath("/div/descendant::*[self::n or self::w]"):
            self.tokens.append(n.text)
            if n.tag == 'w':
                self.word_map.append(len(self.tokens) - 1)
        self.tokens = tuple(self.tokens)
        self.word_map = tuple(self.word_map)

    def get_conc_line(self, word_id, node_size, word_window):
        """
        Given (word_id) generated by get_word(), return:
          - (word_window) word tokens before word_id match, if word_window > 0
          - (node_size) word tokens within match
          - (word_window) word tokens after match, if word_window > 0
        """
        def find_split(start_pos, end_pos):
            # Match start starts at the final left word, and advances until either:
            #  (a) We get to end_pos (the next word or the end of the array)
            #  (b) We find a space, in which case we use the token after
            # <minute> <!> [Come] . . .
            # <minute> <!> <?> [Come] . . .
            # <girls> <,> < > ["] <Come> . . . .
            i = start_pos
            step = 1 if end_pos > start_pos else -1

            while i != end_pos:
                if self.tokens[i].isspace():
                    return i
                    # + step if i + step != end_pos else i
                i += step
            return i

        if word_id >= len(self.word_map):
            # What we want is outside the edge of this chapter
            node_words = []
            node_start = len(self.tokens)
            node_end = len(self.tokens)
        elif node_size == 0:
            # Zero-length node requested
            node_words = []
            node_start = self.word_map[word_id]
            node_end = self.word_map[word_id]
        else:
            # Get list of word positions within our range
            node_words = self.word_map[word_id : word_id + node_size]
            # Fine tune start/end to match spaces
            node_start = find_split(
                node_words[0],
                self.word_map[word_id - 1] + 1 if word_id > 0 else 0
            )
            node_end = find_split(
                node_words[-1],
                self.word_map[word_id + node_size] if word_id + node_size < len(self.word_map) else len(self.tokens)
            )

        if word_window == 0:
            return [
                self.tokens[node_start:node_end] + ([x - node_start for x in node_words],),
            ]

        # Get word positions for the context also
        left_words = self.word_map[max(0, word_id - word_window) : word_id]
        right_words = self.word_map[word_id + node_size : word_id + node_size + word_window]

        return [
            self.tokens[left_words[0]:node_start] + ([x - left_words[0] for x in left_words],) if len(left_words) > 0 else ([],),
            self.tokens[node_start:node_end] + ([x - node_start for x in node_words],),
            self.tokens[node_end:right_words[-1] + 1] + ([x - node_end for x in right_words],) if len(right_words) > 0 else ([],),
        ]

chapter_cache = {}
chapter_pickle_file = os.path.join(CLIC_DIR, 'clic-chapter-cache.pickle')
def get_chapter(session, recStore, id, force=False):
    """
    Given a Cheshire3 (session) and (recStore) and
    an (id) from the store,
    return a Chapter object, either from cache or fresh.
    """
    if force or id not in chapter_cache:
        record = recStore.fetch_record(session, id)
        chapter_cache[id] = Chapter(record.dom, record.digest)

    # Test checksum, if it doesn't match the load the document afresh
    if chapter_cache[id].digest != recStore.fetch_recordMetadata(session, id, 'digest'):
        return get_chapter(session, recStore, id, force=True)

    return chapter_cache[id]

def dump_chapter_cache():
    with open(chapter_pickle_file, 'wb') as f:
        pickle.dump(chapter_cache, f)

def restore_chapter_cache():
    global chapter_cache
    # NB: install.sh tries to create the pickle, but leaves it empty. Ignore this
    if os.path.exists(chapter_pickle_file) and os.path.getsize(chapter_pickle_file) > 0:
        with open(chapter_pickle_file, 'rb') as f:
            chapter_cache = pickle.load(f)
