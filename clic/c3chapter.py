import os
import os.path
import cPickle as pickle
import time

from cheshire3.exceptions import ObjectDoesNotExistException


class Chapter():
    """
    Abstracts a cheshire3 Chapter record, performing all lookups CLiC needs

    Designed to be picked and re-used to save work

    Attributes:
    - tokens: Array of word / non-word tokens
    - word_map: Array of positions in tokens that contain words, i.e. tokens[word_map[4]] is the 4th word
    - book_id: The short name of the book
    - chapter_num: The chapter number within the book
    """
    def __init__(self, tokens, word_map, book_id, chapter_num):
        self.tokens = tokens
        self.word_map = word_map
        self.book_id = book_id
        self.chapter_num = chapter_num

    def get_conc_line(self, word_id, node_size, word_window):
        """
        Given (word_id) generated by get_word(), return:
          - (word_window) word tokens before word_id match, if word_window > 0
          - (node_size) word tokens within match
          - (word_window) word tokens after match, if word_window > 0
        """
        def find_split(start_pos, end_pos):
            # Match start starts at the final left word, and advances until either:
            #  (a) We get to end_pos (the next word or the end of the array)
            #  (b) We find a space, in which case we use the token after
            # <minute> <!> [Come] . . .
            # <minute> <!> <?> [Come] . . .
            # <girls> <,> < > ["] <Come> . . . .
            i = start_pos
            step = 1 if end_pos > start_pos else -1

            while i != end_pos:
                if self.tokens[i].isspace():
                    return i
                    # + step if i + step != end_pos else i
                i += step
            return i

        if word_id >= len(self.word_map):
            # What we want is outside the edge of this chapter
            node_words = []
            node_start = len(self.tokens)
            node_end = len(self.tokens)
        elif node_size == 0:
            # Zero-length node requested
            node_words = []
            node_start = self.word_map[word_id]
            node_end = self.word_map[word_id]
        else:
            # Get list of word positions within our range
            node_words = self.word_map[word_id : word_id + node_size]
            # Fine tune start/end to match spaces
            node_start = find_split(
                node_words[0],
                self.word_map[word_id - 1] + 1 if word_id > 0 else 0
            )
            node_end = find_split(
                node_words[-1],
                self.word_map[word_id + node_size] if word_id + node_size < len(self.word_map) else len(self.tokens)
            )

        if word_window == 0:
            return [
                self.tokens[node_start:node_end] + ([x - node_start for x in node_words],),
            ]

        # Get word positions for the context also
        left_words = self.word_map[max(0, word_id - word_window) : word_id]
        right_words = self.word_map[word_id + node_size : word_id + node_size + word_window]

        return [
            self.tokens[left_words[0]:node_start] + ([x - left_words[0] for x in left_words],) if len(left_words) > 0 else ([],),
            self.tokens[node_start:node_end] + ([x - node_start for x in node_words],),
            self.tokens[node_end:right_words[-1] + 1] + ([x - node_end for x in right_words],) if len(right_words) > 0 else ([],),
        ]
